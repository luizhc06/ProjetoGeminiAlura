{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObF0rzeQo2h1IliX4Ogzuo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizhc06/ProjetoGeminiAlura/blob/main/Projeto_GeminiAlura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cApUlEJrJRcr"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY='COLE AQUI A SUA API_KEY'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "nPefC0dsJ4SO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Listar modelos disponivies*"
      ],
      "metadata": {
        "id": "VbqvqeFbKHO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if \"generateContent\" in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "7mjR5uEcKVX1",
        "outputId": "ec98728f-9499-4a38-ab5f-83797a34145f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "oKh5nVdRMgTw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "NuFl1YnWNJyP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Inicializando o modelo:*"
      ],
      "metadata": {
        "id": "P7FYZ3nvN6SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "K7u7Frf3N-KY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exemplo de criação de texto:*"
      ],
      "metadata": {
        "id": "bi3a33StPbu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Crie um texto de facil entendimento para uma pessoa leiga que não entende sobre tecnologia para ela conhecer o que é e funcionamentos sobre: CPU, RAM, GPU, tipos de armazenamento, fonte de alimentação e gabinete(air-flow)\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "kfOTz5-EPA4E",
        "outputId": "871974d0-2fac-446c-b5bf-f3c3f8bb5591"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**CPU (Unidade Central de Processamento)**\n",
            "\n",
            "Imagine a CPU como o cérebro do seu computador. Ela é responsável por processar e executar instruções, controlando todas as operações do sistema. Quanto mais núcleos e threads a CPU tiver, mais rápido ela poderá processar informações.\n",
            "\n",
            "**RAM (Memória de Acesso Aleatório)**\n",
            "\n",
            "A RAM é a memória de curto prazo do seu computador. Ela armazena dados e instruções que estão sendo usados ativamente. Quanto mais RAM você tiver, mais programas e arquivos poderá executar simultaneamente sem lentidão.\n",
            "\n",
            "**GPU (Unidade de Processamento Gráfico)**\n",
            "\n",
            "A GPU é especializada em processar gráficos. Ela é essencial para jogos, edição de vídeo e outras tarefas que exigem gráficos avançados. Quanto mais poderosa a GPU, melhor será a qualidade gráfica e o desempenho.\n",
            "\n",
            "**Tipos de Armazenamento**\n",
            "\n",
            "* **HDD (Disco Rígido):** Armazenamento mecânico tradicional que usa discos giratórios. É mais lento, mas mais barato e oferece maior capacidade.\n",
            "* **SSD (Unidade de Estado Sólido):** Armazenamento baseado em memória flash que não possui partes móveis. É muito mais rápido que os HDDs, mas também mais caro.\n",
            "\n",
            "**Fonte de Alimentação**\n",
            "\n",
            "A fonte de alimentação fornece energia para todos os componentes do seu computador. Ela deve ser potente o suficiente para atender às necessidades de energia do seu sistema.\n",
            "\n",
            "**Gabinete (Air-flow)**\n",
            "\n",
            "O gabinete é onde todos os componentes do seu computador são montados. Ele deve ter um bom fluxo de ar para evitar o superaquecimento. Os ventiladores ajudam a circular o ar e manter os componentes resfriados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Começando a fazer o ChatBOT:*"
      ],
      "metadata": {
        "id": "zswwma68PTeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "78lZ6qkmPS6V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "dxWx0iWRPy9e",
        "outputId": "e5595a2c-4c7f-47c4-a3e6-5a0ec96b0728"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Qual a capital do japão?\n",
            "Resposta:  Tóquio \n",
            "\n",
            "Esperando prompt: Qual é a comida tipica desse pais?\n",
            "Resposta:  Sushi \n",
            "\n",
            "Esperando prompt: Qual é a marca de carro mais usada neste pais?\n",
            "Resposta:  Toyota \n",
            "\n",
            "Esperando prompt: Qual a marca de processadores e de placa de video sobre computadores este pais mais usa?\n",
            "Resposta:  **Processadores:**\n",
            "\n",
            "* Intel\n",
            "* AMD\n",
            "\n",
            "**Placas de vídeo:**\n",
            "\n",
            "* NVIDIA\n",
            "* AMD Radeon\n",
            "\n",
            "Tanto a Intel quanto a AMD são empresas americanas, mas a AMD tem uma forte presença no Japão. A NVIDIA, com sede nos EUA, também é popular no Japão. \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWyN9g-rTgqk",
        "outputId": "7404f332-cb12-4c5a-8122-247fb27d10a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"Qual a capital do jap\\303\\243o?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"T\\303\\263quio\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual \\303\\251 a comida tipica desse pais?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Sushi\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual \\303\\251 a marca de carro mais usada neste pais?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Toyota\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual a marca de processadores e de placa de video sobre computadores este pais mais usa?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"**Processadores:**\\n\\n* Intel\\n* AMD\\n\\n**Placas de v\\303\\255deo:**\\n\\n* NVIDIA\\n* AMD Radeon\\n\\nTanto a Intel quanto a AMD s\\303\\243o empresas americanas, mas a AMD tem uma forte presen\\303\\247a no Jap\\303\\243o. A NVIDIA, com sede nos EUA, tamb\\303\\251m \\303\\251 popular no Jap\\303\\243o.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Melhorando a visibilidade:*"
      ],
      "metadata": {
        "id": "gggt_zJOTReM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google/dev/tutorials/python/quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico:\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-'*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "YHD8BkEhTQ_B",
        "outputId": "a152e743-9ea6-4fd4-f744-c824e0d4b215"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual a capital do japão?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual é a comida tipica desse pais?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Sushi"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual é a marca de carro mais usada neste pais?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Toyota"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual a marca de processadores e de placa de video sobre computadores este pais mais usa?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: **Processadores:**\n> \n> * Intel\n> * AMD\n> \n> **Placas de vídeo:**\n> \n> * NVIDIA\n> * AMD Radeon\n> \n> Tanto a Intel quanto a AMD são empresas americanas, mas a AMD tem uma forte presença no Japão. A NVIDIA, com sede nos EUA, também é popular no Japão."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8sfqbvIbTB3j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
